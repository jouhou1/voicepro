{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1人目のデータを処理中・・・\n",
      "（進行度:20/100ファイル）\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m（進行度:\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mfiles_number\u001b[39m}\u001b[39;00m\u001b[39mファイル）\u001b[39m\u001b[39m\"\u001b[39m )\n\u001b[1;32m     23\u001b[0m file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dir_name, file_list[i])  \u001b[39m# 音声ファイルへのパス\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m y, sr \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(file_path)  \u001b[39m# 音声ファイルを読み込む\u001b[39;00m\n\u001b[1;32m     25\u001b[0m mfcc \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mfeature\u001b[39m.\u001b[39mmfcc(y, sr)  \u001b[39m# MFCC\u001b[39;00m\n\u001b[1;32m     26\u001b[0m mfcc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage(mfcc, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# 時間平均を取る\u001b[39;00m\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/librosa/core/audio.py:179\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    176\u001b[0m     y \u001b[39m=\u001b[39m to_mono(y)\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m sr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     y \u001b[39m=\u001b[39m resample(y, orig_sr\u001b[39m=\u001b[39;49msr_native, target_sr\u001b[39m=\u001b[39;49msr, res_type\u001b[39m=\u001b[39;49mres_type)\n\u001b[1;32m    181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     sr \u001b[39m=\u001b[39m sr_native\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/librosa/core/audio.py:647\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m     y_hat \u001b[39m=\u001b[39m soxr\u001b[39m.\u001b[39mresample(y\u001b[39m.\u001b[39mT, orig_sr, target_sr, quality\u001b[39m=\u001b[39mres_type)\u001b[39m.\u001b[39mT\n\u001b[1;32m    646\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 647\u001b[0m     y_hat \u001b[39m=\u001b[39m resampy\u001b[39m.\u001b[39;49mresample(y, orig_sr, target_sr, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49mres_type, axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m fix:\n\u001b[1;32m    650\u001b[0m     y_hat \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mfix_length(y_hat, size\u001b[39m=\u001b[39mn_samples, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/resampy/core.py:168\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         resample_f_s(\n\u001b[1;32m    159\u001b[0m             x\u001b[39m.\u001b[39mswapaxes(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, axis),\n\u001b[1;32m    160\u001b[0m             t_out,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m             y\u001b[39m.\u001b[39mswapaxes(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, axis),\n\u001b[1;32m    166\u001b[0m         )\n\u001b[1;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     resample_f_s(\n\u001b[1;32m    169\u001b[0m         x\u001b[39m.\u001b[39;49mswapaxes(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, axis),\n\u001b[1;32m    170\u001b[0m         t_out,\n\u001b[1;32m    171\u001b[0m         interp_win,\n\u001b[1;32m    172\u001b[0m         interp_delta,\n\u001b[1;32m    173\u001b[0m         precision,\n\u001b[1;32m    174\u001b[0m         scale,\n\u001b[1;32m    175\u001b[0m         y\u001b[39m.\u001b[39;49mswapaxes(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, axis),\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/numba/np/ufunc/gufunc.py:168\u001b[0m, in \u001b[0;36mGUFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd(sig)\n\u001b[1;32m    167\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_ufunc()\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mufunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#声優の声データからMFCC（声の特徴量）を抽出し、表にまとめる。\n",
    "\n",
    "X_data = []  # 特徴行列\n",
    "y_data = []  # クラスラベルデータ\n",
    "speakers_number = 7 # 声優の人数\n",
    "files_number = 100 # 一人あたりのサンプルの数\n",
    "\n",
    "for speaker_num in range(1, speakers_number + 1):  # 声優フォルダの数だけ繰り返し処理\n",
    "    clear_output()\n",
    "    # ボイスサンプルがあるフォルダ名\n",
    "    dir_name = f'VoiceSample/{str(speaker_num).zfill(3)}'\n",
    "    file_list = os.listdir(dir_name)\n",
    "    for i in range(files_number):\n",
    "        clear_output()\n",
    "        print(f\"{(i+(speaker_num-1)*files_number)/(files_number*speakers_number)}\")\n",
    "        print(str(speaker_num) + \"人目のデータを処理中・・・\")\n",
    "        print(f\"（進行度:{i+1}/{files_number}ファイル）\" )\n",
    "        file_path = os.path.join(dir_name, file_list[i])  # 音声ファイルへのパス\n",
    "        y, sr = librosa.load(file_path)  # 音声ファイルを読み込む\n",
    "        mfcc = librosa.feature.mfcc(y, sr)  # MFCC\n",
    "        mfcc = np.average(mfcc, axis=1)  # 時間平均を取る\n",
    "        mfcc = mfcc.flatten()\n",
    "        mfcc = mfcc.tolist()\n",
    "        mfcc = mfcc[1:13]  # 低次の係数を取り出す（12次まで取り出すことが多い）\n",
    "        X_data.append(mfcc)\n",
    "        y_data.append(speaker_num)\n",
    "\n",
    "X = pd.DataFrame(X_data, columns=[f'mfcc_{n}' for n in range(1, 13)]) # mfcc_1,mfcc_2,..のように行のタイトルをつける\n",
    "y = pd.DataFrame({'target': y_data}) # targetタイトルを追加\n",
    "\n",
    "df = pd.concat([X, y], axis=1) # 合体！！！！！！\n",
    "df.to_csv('mfcc.csv', index=False)  # csvで保存\n",
    "df.head() # 見せてほしいな"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pycaret.regression import *\n",
    "\n",
    "# 機械学習前の下準備を行う。以下、Pycaretの関数を使う場合このセルを実行してから使うこと\n",
    "\n",
    "mfcc_data = pd.read_csv(\"mfcc.csv\") # MFCCのデータを読み込む\n",
    "# データの前準備(以下、Pycaretの関数を使う場合setupを呼び出してから使うこと)\n",
    "reg = setup(data=mfcc_data, target='target', data_split_shuffle=True, use_gpu=True, silent=True, fold=5, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 機械学習のモデルを複数比較し、精度が高かったモデルを表示する。\n",
    "\n",
    "compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_673f5_row5_col0, #T_673f5_row5_col1, #T_673f5_row5_col2, #T_673f5_row5_col3, #T_673f5_row5_col4, #T_673f5_row5_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_673f5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_673f5_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_673f5_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_673f5_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_673f5_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_673f5_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_673f5_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_673f5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_673f5_row0_col0\" class=\"data row0 col0\" >1.1473</td>\n",
       "      <td id=\"T_673f5_row0_col1\" class=\"data row0 col1\" >1.9948</td>\n",
       "      <td id=\"T_673f5_row0_col2\" class=\"data row0 col2\" >1.4124</td>\n",
       "      <td id=\"T_673f5_row0_col3\" class=\"data row0 col3\" >0.5042</td>\n",
       "      <td id=\"T_673f5_row0_col4\" class=\"data row0 col4\" >0.3792</td>\n",
       "      <td id=\"T_673f5_row0_col5\" class=\"data row0 col5\" >0.6227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_673f5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_673f5_row1_col0\" class=\"data row1 col0\" >1.2014</td>\n",
       "      <td id=\"T_673f5_row1_col1\" class=\"data row1 col1\" >2.3295</td>\n",
       "      <td id=\"T_673f5_row1_col2\" class=\"data row1 col2\" >1.5263</td>\n",
       "      <td id=\"T_673f5_row1_col3\" class=\"data row1 col3\" >0.4368</td>\n",
       "      <td id=\"T_673f5_row1_col4\" class=\"data row1 col4\" >0.3457</td>\n",
       "      <td id=\"T_673f5_row1_col5\" class=\"data row1 col5\" >0.4675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_673f5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_673f5_row2_col0\" class=\"data row2 col0\" >1.0217</td>\n",
       "      <td id=\"T_673f5_row2_col1\" class=\"data row2 col1\" >1.7889</td>\n",
       "      <td id=\"T_673f5_row2_col2\" class=\"data row2 col2\" >1.3375</td>\n",
       "      <td id=\"T_673f5_row2_col3\" class=\"data row2 col3\" >0.5353</td>\n",
       "      <td id=\"T_673f5_row2_col4\" class=\"data row2 col4\" >0.2780</td>\n",
       "      <td id=\"T_673f5_row2_col5\" class=\"data row2 col5\" >0.3223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_673f5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_673f5_row3_col0\" class=\"data row3 col0\" >1.1822</td>\n",
       "      <td id=\"T_673f5_row3_col1\" class=\"data row3 col1\" >2.3691</td>\n",
       "      <td id=\"T_673f5_row3_col2\" class=\"data row3 col2\" >1.5392</td>\n",
       "      <td id=\"T_673f5_row3_col3\" class=\"data row3 col3\" >0.3496</td>\n",
       "      <td id=\"T_673f5_row3_col4\" class=\"data row3 col4\" >0.3393</td>\n",
       "      <td id=\"T_673f5_row3_col5\" class=\"data row3 col5\" >0.3989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_673f5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_673f5_row4_col0\" class=\"data row4 col0\" >1.0508</td>\n",
       "      <td id=\"T_673f5_row4_col1\" class=\"data row4 col1\" >1.8213</td>\n",
       "      <td id=\"T_673f5_row4_col2\" class=\"data row4 col2\" >1.3496</td>\n",
       "      <td id=\"T_673f5_row4_col3\" class=\"data row4 col3\" >0.5464</td>\n",
       "      <td id=\"T_673f5_row4_col4\" class=\"data row4 col4\" >0.3229</td>\n",
       "      <td id=\"T_673f5_row4_col5\" class=\"data row4 col5\" >0.4456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_673f5_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_673f5_row5_col0\" class=\"data row5 col0\" >1.1207</td>\n",
       "      <td id=\"T_673f5_row5_col1\" class=\"data row5 col1\" >2.0607</td>\n",
       "      <td id=\"T_673f5_row5_col2\" class=\"data row5 col2\" >1.4330</td>\n",
       "      <td id=\"T_673f5_row5_col3\" class=\"data row5 col3\" >0.4745</td>\n",
       "      <td id=\"T_673f5_row5_col4\" class=\"data row5 col4\" >0.3330</td>\n",
       "      <td id=\"T_673f5_row5_col5\" class=\"data row5 col5\" >0.4514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_673f5_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_673f5_row6_col0\" class=\"data row6 col0\" >0.0717</td>\n",
       "      <td id=\"T_673f5_row6_col1\" class=\"data row6 col1\" >0.2461</td>\n",
       "      <td id=\"T_673f5_row6_col2\" class=\"data row6 col2\" >0.0854</td>\n",
       "      <td id=\"T_673f5_row6_col3\" class=\"data row6 col3\" >0.0732</td>\n",
       "      <td id=\"T_673f5_row6_col4\" class=\"data row6 col4\" >0.0331</td>\n",
       "      <td id=\"T_673f5_row6_col5\" class=\"data row6 col5\" >0.0991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d99d7f0f6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_24a23\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_24a23_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_24a23_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_24a23_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_24a23_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_24a23_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_24a23_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_24a23_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_24a23_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_24a23_row0_col0\" class=\"data row0 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_24a23_row0_col1\" class=\"data row0 col1\" >1.0134</td>\n",
       "      <td id=\"T_24a23_row0_col2\" class=\"data row0 col2\" >1.6936</td>\n",
       "      <td id=\"T_24a23_row0_col3\" class=\"data row0 col3\" >1.3014</td>\n",
       "      <td id=\"T_24a23_row0_col4\" class=\"data row0 col4\" >0.5689</td>\n",
       "      <td id=\"T_24a23_row0_col5\" class=\"data row0 col5\" >0.3122</td>\n",
       "      <td id=\"T_24a23_row0_col6\" class=\"data row0 col6\" >0.4253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d99f3f9e940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.regression import *\n",
    "# 最も精度が高かったモデルを生成\n",
    "\n",
    "model = create_model('et') # モデルを生成（）\n",
    "#tuned_model = tune_model(model) # モデルを調整...すると精度落ちるの何...しないほうがいいのか？\n",
    "predict_data = predict_model(model) # 既存のデータで予測\n",
    "predict_data.to_csv('predict_result.csv', index=False)  # csvで保存\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=[],\n",
       "                                       display_types=False, features_todrop=[],\n",
       "                                       id_columns=[], ml_usecase='regression',\n",
       "                                       numerical_features=[], target='target',\n",
       "                                       time_features=[])),\n",
       "                 ('imputer',\n",
       "                  Simple_Imputer(categorical_strategy='not_available',\n",
       "                                 fill_value_categorical=None,\n",
       "                                 fill_value_numerical=None,\n",
       "                                 numeric_strategy...\n",
       "                  ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0,\n",
       "                                      criterion='mse', max_depth=None,\n",
       "                                      max_features='auto', max_leaf_nodes=None,\n",
       "                                      max_samples=None,\n",
       "                                      min_impurity_decrease=0.0,\n",
       "                                      min_impurity_split=None,\n",
       "                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                      min_weight_fraction_leaf=0.0,\n",
       "                                      n_estimators=100, n_jobs=-1,\n",
       "                                      oob_score=False, random_state=4927,\n",
       "                                      verbose=0, warm_start=False)]],\n",
       "          verbose=False),\n",
       " 'Final Model.pkl')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = finalize_model(model)\n",
    "save_model(final_model,'Final Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "from pycaret.regression import *\n",
    "\n",
    "final_model = load_model('Final Model') # モデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "録音開始\n",
      "録音終了\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8879/3780763905.py:18: RuntimeWarning: invalid value encountered in true_divide\n",
      "  data = data / data.max() * np.iinfo(np.int16).max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCCを抽出しています・・・\n",
      "処理完了\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8879/3780763905.py:43: FutureWarning: Pass y=[0. 0. 0. ... 0. 0. 0.], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mfcc = librosa.feature.mfcc(y, sr)  # MFCC\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "#音声を録音\n",
    "\n",
    "FILE_NAME = 'my_recording.wav'  # 保存するファイル名\n",
    "wave_length = 5  # 録音する長さ（秒）\n",
    "sample_rate = 16_000  # サンプリング周波数\n",
    "\n",
    "print(\"録音開始\")\n",
    "# 録音開始（wave_length秒間録音。wait で録音し終わるまで待つ）\n",
    "data = sd.rec(int(wave_length * sample_rate), sample_rate, channels=1)\n",
    "sd.wait()\n",
    "print(\"録音終了\")\n",
    "\n",
    "# ノーマライズ。量子化ビット16bitで録音するので int16 の範囲で最大化する\n",
    "data = data / data.max() * np.iinfo(np.int16).max\n",
    "\n",
    "# float -> int\n",
    "data = data.astype(np.int16)\n",
    "\n",
    "# ファイル保存\n",
    "with wave.open(FILE_NAME, mode='wb') as wb:\n",
    "    wb.setnchannels(1)  # モノラル\n",
    "    wb.setsampwidth(2)  # 16bit=2byte\n",
    "    wb.setframerate(sample_rate)\n",
    "    wb.writeframes(data.tobytes())  # バイト列に変換\n",
    "\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "###MFCCを抽出###\n",
    "print(\"MFCCを抽出しています・・・\")\n",
    "\n",
    "data = []\n",
    "TEST_FILE_NAME = \"test.wav\"\n",
    "\n",
    "test = False\n",
    "\n",
    "y, sr = librosa.load(TEST_FILE_NAME if test else FILE_NAME)  # 音声ファイルを読み込む\n",
    "mfcc = librosa.feature.mfcc(y, sr)  # MFCC\n",
    "mfcc = np.average(mfcc, axis=1)  # 時間平均を取る\n",
    "mfcc = mfcc.flatten()\n",
    "mfcc = mfcc.tolist()\n",
    "mfcc = mfcc[1:13]  # 低次の係数を取り出す（12次まで取り出すことが多い）\n",
    "data.append(mfcc)\n",
    "\n",
    "df = pd.DataFrame(data, columns=[f'mfcc_{n}' for n in range(1, 13)])\n",
    "\n",
    "df.to_csv('mfcc_my_recording.csv', index=False)  # csvで保存\n",
    "df.head()\n",
    "\n",
    "print(\"処理完了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>mfcc_11</th>\n",
       "      <th>mfcc_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.791355</td>\n",
       "      <td>-18.600464</td>\n",
       "      <td>18.558226</td>\n",
       "      <td>-1.541007</td>\n",
       "      <td>-2.50288</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>-0.349908</td>\n",
       "      <td>-7.095498</td>\n",
       "      <td>1.180879</td>\n",
       "      <td>-10.101668</td>\n",
       "      <td>4.389037</td>\n",
       "      <td>-3.882792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mfcc_1     mfcc_2     mfcc_3    mfcc_4   mfcc_5    mfcc_6    mfcc_7  \\\n",
       "0  61.791355 -18.600464  18.558226 -1.541007 -2.50288  0.355464 -0.349908   \n",
       "\n",
       "     mfcc_8    mfcc_9    mfcc_10   mfcc_11   mfcc_12  \n",
       "0 -7.095498  1.180879 -10.101668  4.389037 -3.882792  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "あなたの声は鬼頭明里に似ています。\n",
      "予測値：2.66\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal, ROUND_HALF_UP, ROUND_HALF_EVEN\n",
    "from pycaret.regression import *\n",
    "\n",
    "#録音した音声データからどの声優に似ているかを特定\n",
    "\n",
    "actors = [\"下野紘\", \"花江夏樹\", \"梶裕貴\", \"沢城みゆき\", \"鬼頭明里\", \"水瀬いのり\", \"悠木碧\"]\n",
    "\n",
    "predict_my_recording = predict_model(final_model, data = pd.read_csv(\"mfcc_my_recording.csv\")) # 未知データを予測\n",
    "predict_label = predict_my_recording.at[0, \"Label\"] # 予測データを取得（小数点数）\n",
    "voice_actor_number = Decimal(str(predict_label)).quantize(Decimal('0'), rounding=ROUND_HALF_UP) # 整数に四捨五入\n",
    "print(\"あなたの声は\" + actors[int(voice_actor_number-1)] + \"に似ています。\")\n",
    "print(\"予測値：\" + str(predict_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voicepro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f851e7d60498e4c856c45d591b0ef68acd2607c354303225ef1533b02fefcf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
