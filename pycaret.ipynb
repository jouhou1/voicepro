{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%完了\n",
      "7人目のデータを処理中・・・\n",
      "（進行度:100/100ファイル）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8879/2882801715.py:26: FutureWarning: Pass y=[-3.0901801e-06 -4.7229732e-06  1.2742006e-05 ... -3.3230467e-06\n",
      " -1.4371163e-06  0.0000000e+00], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mfcc = librosa.feature.mfcc(y, sr)  # MFCC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>mfcc_11</th>\n",
       "      <th>mfcc_12</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.305939</td>\n",
       "      <td>-2.388980</td>\n",
       "      <td>28.821922</td>\n",
       "      <td>8.106466</td>\n",
       "      <td>-7.335474</td>\n",
       "      <td>-5.098837</td>\n",
       "      <td>2.708056</td>\n",
       "      <td>1.108589</td>\n",
       "      <td>-6.039336</td>\n",
       "      <td>-11.022418</td>\n",
       "      <td>8.562423</td>\n",
       "      <td>-8.208080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.389778</td>\n",
       "      <td>15.316972</td>\n",
       "      <td>29.470976</td>\n",
       "      <td>15.136189</td>\n",
       "      <td>7.453907</td>\n",
       "      <td>-4.679848</td>\n",
       "      <td>6.583255</td>\n",
       "      <td>-3.255087</td>\n",
       "      <td>2.030280</td>\n",
       "      <td>-12.806031</td>\n",
       "      <td>9.289038</td>\n",
       "      <td>-7.932013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.034988</td>\n",
       "      <td>19.946007</td>\n",
       "      <td>42.861015</td>\n",
       "      <td>15.739766</td>\n",
       "      <td>-5.527338</td>\n",
       "      <td>0.597292</td>\n",
       "      <td>3.899351</td>\n",
       "      <td>-1.708565</td>\n",
       "      <td>-6.449223</td>\n",
       "      <td>-6.763590</td>\n",
       "      <td>11.951451</td>\n",
       "      <td>-12.204566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.402969</td>\n",
       "      <td>14.758104</td>\n",
       "      <td>36.634586</td>\n",
       "      <td>19.574112</td>\n",
       "      <td>-5.123018</td>\n",
       "      <td>-3.361386</td>\n",
       "      <td>4.112405</td>\n",
       "      <td>-0.293475</td>\n",
       "      <td>-1.699620</td>\n",
       "      <td>-10.678855</td>\n",
       "      <td>12.195671</td>\n",
       "      <td>-13.852660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.733459</td>\n",
       "      <td>15.617436</td>\n",
       "      <td>38.703354</td>\n",
       "      <td>16.677921</td>\n",
       "      <td>-3.071551</td>\n",
       "      <td>-1.830640</td>\n",
       "      <td>5.379351</td>\n",
       "      <td>0.139020</td>\n",
       "      <td>-8.512769</td>\n",
       "      <td>-13.017569</td>\n",
       "      <td>8.190866</td>\n",
       "      <td>-15.577478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mfcc_1     mfcc_2     mfcc_3     mfcc_4    mfcc_5    mfcc_6    mfcc_7  \\\n",
       "0  79.305939  -2.388980  28.821922   8.106466 -7.335474 -5.098837  2.708056   \n",
       "1  46.389778  15.316972  29.470976  15.136189  7.453907 -4.679848  6.583255   \n",
       "2  97.034988  19.946007  42.861015  15.739766 -5.527338  0.597292  3.899351   \n",
       "3  84.402969  14.758104  36.634586  19.574112 -5.123018 -3.361386  4.112405   \n",
       "4  94.733459  15.617436  38.703354  16.677921 -3.071551 -1.830640  5.379351   \n",
       "\n",
       "     mfcc_8    mfcc_9    mfcc_10    mfcc_11    mfcc_12  target  \n",
       "0  1.108589 -6.039336 -11.022418   8.562423  -8.208080       1  \n",
       "1 -3.255087  2.030280 -12.806031   9.289038  -7.932013       1  \n",
       "2 -1.708565 -6.449223  -6.763590  11.951451 -12.204566       1  \n",
       "3 -0.293475 -1.699620 -10.678855  12.195671 -13.852660       1  \n",
       "4  0.139020 -8.512769 -13.017569   8.190866 -15.577478       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#声優の声データからMFCC（声の特徴量）を抽出し、表にまとめる。\n",
    "\n",
    "X_data = []  # 特徴行列\n",
    "y_data = []  # クラスラベルデータ\n",
    "speakers_number = 7 # 声優の人数\n",
    "files_number = 100 # 一人あたりのサンプルの数\n",
    "\n",
    "for speaker_num in range(1, speakers_number + 1):  # 声優フォルダの数だけ繰り返し処理\n",
    "    clear_output()\n",
    "    # ボイスサンプルがあるフォルダ名\n",
    "    dir_name = f'VoiceSample/{str(speaker_num).zfill(3)}'\n",
    "    file_list = os.listdir(dir_name)\n",
    "    for i in range(files_number):\n",
    "        clear_output()\n",
    "        print(f\"{int((i+(speaker_num-1)*files_number)/(files_number*speakers_number)*100)}%完了\")\n",
    "        print(str(speaker_num) + \"人目のデータを処理中・・・\")\n",
    "        print(f\"（進行度:{i+1}/{files_number}ファイル）\" )\n",
    "        file_path = os.path.join(dir_name, file_list[i])  # 音声ファイルへのパス\n",
    "        y, sr = librosa.load(file_path)  # 音声ファイルを読み込む\n",
    "        mfcc = librosa.feature.mfcc(y, sr)  # MFCC\n",
    "        mfcc = np.average(mfcc, axis=1)  # 時間平均を取る\n",
    "        mfcc = mfcc.flatten()\n",
    "        mfcc = mfcc.tolist()\n",
    "        mfcc = mfcc[1:13]  # 低次の係数を取り出す（12次まで取り出すことが多い）\n",
    "        X_data.append(mfcc)\n",
    "        y_data.append(speaker_num)\n",
    "\n",
    "X = pd.DataFrame(X_data, columns=[f'mfcc_{n}' for n in range(1, 13)]) # mfcc_1,mfcc_2,..のように行のタイトルをつける\n",
    "y = pd.DataFrame({'target': y_data}) # targetタイトルを追加\n",
    "\n",
    "df = pd.concat([X, y], axis=1) # 合体！！！！！！\n",
    "df.to_csv('mfcc.csv', index=False)  # csvで保存\n",
    "df.head() # 見せてほしいな"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5d65c th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5d65c_row0_col0, #T_5d65c_row1_col0, #T_5d65c_row1_col1, #T_5d65c_row1_col2, #T_5d65c_row1_col3, #T_5d65c_row1_col4, #T_5d65c_row1_col5, #T_5d65c_row1_col6, #T_5d65c_row2_col0, #T_5d65c_row2_col1, #T_5d65c_row2_col2, #T_5d65c_row2_col3, #T_5d65c_row2_col4, #T_5d65c_row2_col5, #T_5d65c_row2_col6, #T_5d65c_row3_col0, #T_5d65c_row3_col1, #T_5d65c_row3_col2, #T_5d65c_row3_col3, #T_5d65c_row3_col4, #T_5d65c_row3_col5, #T_5d65c_row3_col6, #T_5d65c_row4_col0, #T_5d65c_row4_col1, #T_5d65c_row4_col2, #T_5d65c_row4_col3, #T_5d65c_row4_col4, #T_5d65c_row4_col5, #T_5d65c_row4_col6, #T_5d65c_row5_col0, #T_5d65c_row5_col1, #T_5d65c_row5_col2, #T_5d65c_row5_col3, #T_5d65c_row5_col4, #T_5d65c_row5_col5, #T_5d65c_row5_col6, #T_5d65c_row6_col0, #T_5d65c_row6_col1, #T_5d65c_row6_col2, #T_5d65c_row6_col3, #T_5d65c_row6_col4, #T_5d65c_row6_col5, #T_5d65c_row6_col6, #T_5d65c_row7_col0, #T_5d65c_row7_col1, #T_5d65c_row7_col2, #T_5d65c_row7_col3, #T_5d65c_row7_col4, #T_5d65c_row7_col5, #T_5d65c_row7_col6, #T_5d65c_row8_col0, #T_5d65c_row8_col1, #T_5d65c_row8_col2, #T_5d65c_row8_col3, #T_5d65c_row8_col4, #T_5d65c_row8_col5, #T_5d65c_row8_col6, #T_5d65c_row9_col0, #T_5d65c_row9_col1, #T_5d65c_row9_col2, #T_5d65c_row9_col3, #T_5d65c_row9_col4, #T_5d65c_row9_col5, #T_5d65c_row9_col6, #T_5d65c_row10_col0, #T_5d65c_row10_col1, #T_5d65c_row10_col2, #T_5d65c_row10_col3, #T_5d65c_row10_col4, #T_5d65c_row10_col5, #T_5d65c_row10_col6, #T_5d65c_row11_col0, #T_5d65c_row11_col1, #T_5d65c_row11_col2, #T_5d65c_row11_col3, #T_5d65c_row11_col4, #T_5d65c_row11_col5, #T_5d65c_row11_col6, #T_5d65c_row12_col0, #T_5d65c_row12_col1, #T_5d65c_row12_col2, #T_5d65c_row12_col3, #T_5d65c_row12_col4, #T_5d65c_row12_col5, #T_5d65c_row12_col6, #T_5d65c_row13_col0, #T_5d65c_row13_col1, #T_5d65c_row13_col2, #T_5d65c_row13_col3, #T_5d65c_row13_col4, #T_5d65c_row13_col5, #T_5d65c_row13_col6, #T_5d65c_row14_col0, #T_5d65c_row14_col1, #T_5d65c_row14_col2, #T_5d65c_row14_col3, #T_5d65c_row14_col4, #T_5d65c_row14_col5, #T_5d65c_row14_col6, #T_5d65c_row15_col0, #T_5d65c_row15_col1, #T_5d65c_row15_col2, #T_5d65c_row15_col3, #T_5d65c_row15_col4, #T_5d65c_row15_col5, #T_5d65c_row15_col6, #T_5d65c_row16_col0, #T_5d65c_row16_col1, #T_5d65c_row16_col2, #T_5d65c_row16_col3, #T_5d65c_row16_col4, #T_5d65c_row16_col5, #T_5d65c_row16_col6, #T_5d65c_row17_col0, #T_5d65c_row17_col1, #T_5d65c_row17_col2, #T_5d65c_row17_col3, #T_5d65c_row17_col4, #T_5d65c_row17_col5, #T_5d65c_row17_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5d65c_row0_col1, #T_5d65c_row0_col2, #T_5d65c_row0_col3, #T_5d65c_row0_col4, #T_5d65c_row0_col5, #T_5d65c_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_5d65c_row0_col7, #T_5d65c_row1_col7, #T_5d65c_row2_col7, #T_5d65c_row3_col7, #T_5d65c_row4_col7, #T_5d65c_row5_col7, #T_5d65c_row6_col7, #T_5d65c_row7_col7, #T_5d65c_row8_col7, #T_5d65c_row9_col7, #T_5d65c_row10_col7, #T_5d65c_row11_col7, #T_5d65c_row12_col7, #T_5d65c_row14_col7, #T_5d65c_row15_col7, #T_5d65c_row16_col7, #T_5d65c_row17_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_5d65c_row13_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5d65c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5d65c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_5d65c_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_5d65c_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_5d65c_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_5d65c_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_5d65c_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_5d65c_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_5d65c_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_5d65c_row0_col0\" class=\"data row0 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_5d65c_row0_col1\" class=\"data row0 col1\" >0.8543</td>\n",
       "      <td id=\"T_5d65c_row0_col2\" class=\"data row0 col2\" >1.4171</td>\n",
       "      <td id=\"T_5d65c_row0_col3\" class=\"data row0 col3\" >1.1903</td>\n",
       "      <td id=\"T_5d65c_row0_col4\" class=\"data row0 col4\" >0.6434</td>\n",
       "      <td id=\"T_5d65c_row0_col5\" class=\"data row0 col5\" >0.2759</td>\n",
       "      <td id=\"T_5d65c_row0_col6\" class=\"data row0 col6\" >0.3343</td>\n",
       "      <td id=\"T_5d65c_row0_col7\" class=\"data row0 col7\" >2.3240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row1\" class=\"row_heading level0 row1\" >rf</th>\n",
       "      <td id=\"T_5d65c_row1_col0\" class=\"data row1 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_5d65c_row1_col1\" class=\"data row1 col1\" >0.8802</td>\n",
       "      <td id=\"T_5d65c_row1_col2\" class=\"data row1 col2\" >1.5283</td>\n",
       "      <td id=\"T_5d65c_row1_col3\" class=\"data row1 col3\" >1.2352</td>\n",
       "      <td id=\"T_5d65c_row1_col4\" class=\"data row1 col4\" >0.6158</td>\n",
       "      <td id=\"T_5d65c_row1_col5\" class=\"data row1 col5\" >0.2833</td>\n",
       "      <td id=\"T_5d65c_row1_col6\" class=\"data row1 col6\" >0.3409</td>\n",
       "      <td id=\"T_5d65c_row1_col7\" class=\"data row1 col7\" >2.7740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row2\" class=\"row_heading level0 row2\" >gbr</th>\n",
       "      <td id=\"T_5d65c_row2_col0\" class=\"data row2 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_5d65c_row2_col1\" class=\"data row2 col1\" >0.9651</td>\n",
       "      <td id=\"T_5d65c_row2_col2\" class=\"data row2 col2\" >1.7196</td>\n",
       "      <td id=\"T_5d65c_row2_col3\" class=\"data row2 col3\" >1.3108</td>\n",
       "      <td id=\"T_5d65c_row2_col4\" class=\"data row2 col4\" >0.5686</td>\n",
       "      <td id=\"T_5d65c_row2_col5\" class=\"data row2 col5\" >0.3027</td>\n",
       "      <td id=\"T_5d65c_row2_col6\" class=\"data row2 col6\" >0.3734</td>\n",
       "      <td id=\"T_5d65c_row2_col7\" class=\"data row2 col7\" >0.4080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row3\" class=\"row_heading level0 row3\" >lightgbm</th>\n",
       "      <td id=\"T_5d65c_row3_col0\" class=\"data row3 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_5d65c_row3_col1\" class=\"data row3 col1\" >0.9571</td>\n",
       "      <td id=\"T_5d65c_row3_col2\" class=\"data row3 col2\" >1.7526</td>\n",
       "      <td id=\"T_5d65c_row3_col3\" class=\"data row3 col3\" >1.3227</td>\n",
       "      <td id=\"T_5d65c_row3_col4\" class=\"data row3 col4\" >0.5597</td>\n",
       "      <td id=\"T_5d65c_row3_col5\" class=\"data row3 col5\" >0.3045</td>\n",
       "      <td id=\"T_5d65c_row3_col6\" class=\"data row3 col6\" >0.3645</td>\n",
       "      <td id=\"T_5d65c_row3_col7\" class=\"data row3 col7\" >0.4860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row4\" class=\"row_heading level0 row4\" >knn</th>\n",
       "      <td id=\"T_5d65c_row4_col0\" class=\"data row4 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_5d65c_row4_col1\" class=\"data row4 col1\" >0.9351</td>\n",
       "      <td id=\"T_5d65c_row4_col2\" class=\"data row4 col2\" >1.7810</td>\n",
       "      <td id=\"T_5d65c_row4_col3\" class=\"data row4 col3\" >1.3335</td>\n",
       "      <td id=\"T_5d65c_row4_col4\" class=\"data row4 col4\" >0.5512</td>\n",
       "      <td id=\"T_5d65c_row4_col5\" class=\"data row4 col5\" >0.3031</td>\n",
       "      <td id=\"T_5d65c_row4_col6\" class=\"data row4 col6\" >0.3624</td>\n",
       "      <td id=\"T_5d65c_row4_col7\" class=\"data row4 col7\" >0.2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row5\" class=\"row_heading level0 row5\" >ada</th>\n",
       "      <td id=\"T_5d65c_row5_col0\" class=\"data row5 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_5d65c_row5_col1\" class=\"data row5 col1\" >1.0784</td>\n",
       "      <td id=\"T_5d65c_row5_col2\" class=\"data row5 col2\" >1.8743</td>\n",
       "      <td id=\"T_5d65c_row5_col3\" class=\"data row5 col3\" >1.3685</td>\n",
       "      <td id=\"T_5d65c_row5_col4\" class=\"data row5 col4\" >0.5295</td>\n",
       "      <td id=\"T_5d65c_row5_col5\" class=\"data row5 col5\" >0.3239</td>\n",
       "      <td id=\"T_5d65c_row5_col6\" class=\"data row5 col6\" >0.4520</td>\n",
       "      <td id=\"T_5d65c_row5_col7\" class=\"data row5 col7\" >0.3720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row6\" class=\"row_heading level0 row6\" >br</th>\n",
       "      <td id=\"T_5d65c_row6_col0\" class=\"data row6 col0\" >Bayesian Ridge</td>\n",
       "      <td id=\"T_5d65c_row6_col1\" class=\"data row6 col1\" >1.1108</td>\n",
       "      <td id=\"T_5d65c_row6_col2\" class=\"data row6 col2\" >1.9967</td>\n",
       "      <td id=\"T_5d65c_row6_col3\" class=\"data row6 col3\" >1.4123</td>\n",
       "      <td id=\"T_5d65c_row6_col4\" class=\"data row6 col4\" >0.4984</td>\n",
       "      <td id=\"T_5d65c_row6_col5\" class=\"data row6 col5\" >0.3252</td>\n",
       "      <td id=\"T_5d65c_row6_col6\" class=\"data row6 col6\" >0.4332</td>\n",
       "      <td id=\"T_5d65c_row6_col7\" class=\"data row6 col7\" >0.0520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row7\" class=\"row_heading level0 row7\" >ridge</th>\n",
       "      <td id=\"T_5d65c_row7_col0\" class=\"data row7 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_5d65c_row7_col1\" class=\"data row7 col1\" >1.1122</td>\n",
       "      <td id=\"T_5d65c_row7_col2\" class=\"data row7 col2\" >2.0034</td>\n",
       "      <td id=\"T_5d65c_row7_col3\" class=\"data row7 col3\" >1.4143</td>\n",
       "      <td id=\"T_5d65c_row7_col4\" class=\"data row7 col4\" >0.4973</td>\n",
       "      <td id=\"T_5d65c_row7_col5\" class=\"data row7 col5\" >0.3256</td>\n",
       "      <td id=\"T_5d65c_row7_col6\" class=\"data row7 col6\" >0.4314</td>\n",
       "      <td id=\"T_5d65c_row7_col7\" class=\"data row7 col7\" >0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row8\" class=\"row_heading level0 row8\" >lar</th>\n",
       "      <td id=\"T_5d65c_row8_col0\" class=\"data row8 col0\" >Least Angle Regression</td>\n",
       "      <td id=\"T_5d65c_row8_col1\" class=\"data row8 col1\" >1.1122</td>\n",
       "      <td id=\"T_5d65c_row8_col2\" class=\"data row8 col2\" >2.0034</td>\n",
       "      <td id=\"T_5d65c_row8_col3\" class=\"data row8 col3\" >1.4143</td>\n",
       "      <td id=\"T_5d65c_row8_col4\" class=\"data row8 col4\" >0.4973</td>\n",
       "      <td id=\"T_5d65c_row8_col5\" class=\"data row8 col5\" >0.3256</td>\n",
       "      <td id=\"T_5d65c_row8_col6\" class=\"data row8 col6\" >0.4314</td>\n",
       "      <td id=\"T_5d65c_row8_col7\" class=\"data row8 col7\" >0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row9\" class=\"row_heading level0 row9\" >lr</th>\n",
       "      <td id=\"T_5d65c_row9_col0\" class=\"data row9 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_5d65c_row9_col1\" class=\"data row9 col1\" >1.1122</td>\n",
       "      <td id=\"T_5d65c_row9_col2\" class=\"data row9 col2\" >2.0034</td>\n",
       "      <td id=\"T_5d65c_row9_col3\" class=\"data row9 col3\" >1.4143</td>\n",
       "      <td id=\"T_5d65c_row9_col4\" class=\"data row9 col4\" >0.4973</td>\n",
       "      <td id=\"T_5d65c_row9_col5\" class=\"data row9 col5\" >0.3256</td>\n",
       "      <td id=\"T_5d65c_row9_col6\" class=\"data row9 col6\" >0.4314</td>\n",
       "      <td id=\"T_5d65c_row9_col7\" class=\"data row9 col7\" >0.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row10\" class=\"row_heading level0 row10\" >en</th>\n",
       "      <td id=\"T_5d65c_row10_col0\" class=\"data row10 col0\" >Elastic Net</td>\n",
       "      <td id=\"T_5d65c_row10_col1\" class=\"data row10 col1\" >1.1223</td>\n",
       "      <td id=\"T_5d65c_row10_col2\" class=\"data row10 col2\" >2.0214</td>\n",
       "      <td id=\"T_5d65c_row10_col3\" class=\"data row10 col3\" >1.4210</td>\n",
       "      <td id=\"T_5d65c_row10_col4\" class=\"data row10 col4\" >0.4910</td>\n",
       "      <td id=\"T_5d65c_row10_col5\" class=\"data row10 col5\" >0.3280</td>\n",
       "      <td id=\"T_5d65c_row10_col6\" class=\"data row10 col6\" >0.4412</td>\n",
       "      <td id=\"T_5d65c_row10_col7\" class=\"data row10 col7\" >0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row11\" class=\"row_heading level0 row11\" >huber</th>\n",
       "      <td id=\"T_5d65c_row11_col0\" class=\"data row11 col0\" >Huber Regressor</td>\n",
       "      <td id=\"T_5d65c_row11_col1\" class=\"data row11 col1\" >1.0892</td>\n",
       "      <td id=\"T_5d65c_row11_col2\" class=\"data row11 col2\" >2.0326</td>\n",
       "      <td id=\"T_5d65c_row11_col3\" class=\"data row11 col3\" >1.4247</td>\n",
       "      <td id=\"T_5d65c_row11_col4\" class=\"data row11 col4\" >0.4895</td>\n",
       "      <td id=\"T_5d65c_row11_col5\" class=\"data row11 col5\" >0.3244</td>\n",
       "      <td id=\"T_5d65c_row11_col6\" class=\"data row11 col6\" >0.4038</td>\n",
       "      <td id=\"T_5d65c_row11_col7\" class=\"data row11 col7\" >0.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row12\" class=\"row_heading level0 row12\" >lasso</th>\n",
       "      <td id=\"T_5d65c_row12_col0\" class=\"data row12 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_5d65c_row12_col1\" class=\"data row12 col1\" >1.1417</td>\n",
       "      <td id=\"T_5d65c_row12_col2\" class=\"data row12 col2\" >2.0759</td>\n",
       "      <td id=\"T_5d65c_row12_col3\" class=\"data row12 col3\" >1.4398</td>\n",
       "      <td id=\"T_5d65c_row12_col4\" class=\"data row12 col4\" >0.4765</td>\n",
       "      <td id=\"T_5d65c_row12_col5\" class=\"data row12 col5\" >0.3330</td>\n",
       "      <td id=\"T_5d65c_row12_col6\" class=\"data row12 col6\" >0.4529</td>\n",
       "      <td id=\"T_5d65c_row12_col7\" class=\"data row12 col7\" >0.0820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row13\" class=\"row_heading level0 row13\" >omp</th>\n",
       "      <td id=\"T_5d65c_row13_col0\" class=\"data row13 col0\" >Orthogonal Matching Pursuit</td>\n",
       "      <td id=\"T_5d65c_row13_col1\" class=\"data row13 col1\" >1.2459</td>\n",
       "      <td id=\"T_5d65c_row13_col2\" class=\"data row13 col2\" >2.4802</td>\n",
       "      <td id=\"T_5d65c_row13_col3\" class=\"data row13 col3\" >1.5731</td>\n",
       "      <td id=\"T_5d65c_row13_col4\" class=\"data row13 col4\" >0.3731</td>\n",
       "      <td id=\"T_5d65c_row13_col5\" class=\"data row13 col5\" >0.3545</td>\n",
       "      <td id=\"T_5d65c_row13_col6\" class=\"data row13 col6\" >0.4827</td>\n",
       "      <td id=\"T_5d65c_row13_col7\" class=\"data row13 col7\" >0.0420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row14\" class=\"row_heading level0 row14\" >dt</th>\n",
       "      <td id=\"T_5d65c_row14_col0\" class=\"data row14 col0\" >Decision Tree Regressor</td>\n",
       "      <td id=\"T_5d65c_row14_col1\" class=\"data row14 col1\" >1.1947</td>\n",
       "      <td id=\"T_5d65c_row14_col2\" class=\"data row14 col2\" >3.7068</td>\n",
       "      <td id=\"T_5d65c_row14_col3\" class=\"data row14 col3\" >1.9199</td>\n",
       "      <td id=\"T_5d65c_row14_col4\" class=\"data row14 col4\" >0.0616</td>\n",
       "      <td id=\"T_5d65c_row14_col5\" class=\"data row14 col5\" >0.4260</td>\n",
       "      <td id=\"T_5d65c_row14_col6\" class=\"data row14 col6\" >0.4302</td>\n",
       "      <td id=\"T_5d65c_row14_col7\" class=\"data row14 col7\" >0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row15\" class=\"row_heading level0 row15\" >llar</th>\n",
       "      <td id=\"T_5d65c_row15_col0\" class=\"data row15 col0\" >Lasso Least Angle Regression</td>\n",
       "      <td id=\"T_5d65c_row15_col1\" class=\"data row15 col1\" >1.7101</td>\n",
       "      <td id=\"T_5d65c_row15_col2\" class=\"data row15 col2\" >3.9994</td>\n",
       "      <td id=\"T_5d65c_row15_col3\" class=\"data row15 col3\" >1.9989</td>\n",
       "      <td id=\"T_5d65c_row15_col4\" class=\"data row15 col4\" >-0.0025</td>\n",
       "      <td id=\"T_5d65c_row15_col5\" class=\"data row15 col5\" >0.4643</td>\n",
       "      <td id=\"T_5d65c_row15_col6\" class=\"data row15 col6\" >0.7533</td>\n",
       "      <td id=\"T_5d65c_row15_col7\" class=\"data row15 col7\" >0.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row16\" class=\"row_heading level0 row16\" >dummy</th>\n",
       "      <td id=\"T_5d65c_row16_col0\" class=\"data row16 col0\" >Dummy Regressor</td>\n",
       "      <td id=\"T_5d65c_row16_col1\" class=\"data row16 col1\" >1.7101</td>\n",
       "      <td id=\"T_5d65c_row16_col2\" class=\"data row16 col2\" >3.9994</td>\n",
       "      <td id=\"T_5d65c_row16_col3\" class=\"data row16 col3\" >1.9989</td>\n",
       "      <td id=\"T_5d65c_row16_col4\" class=\"data row16 col4\" >-0.0025</td>\n",
       "      <td id=\"T_5d65c_row16_col5\" class=\"data row16 col5\" >0.4643</td>\n",
       "      <td id=\"T_5d65c_row16_col6\" class=\"data row16 col6\" >0.7533</td>\n",
       "      <td id=\"T_5d65c_row16_col7\" class=\"data row16 col7\" >0.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d65c_level0_row17\" class=\"row_heading level0 row17\" >par</th>\n",
       "      <td id=\"T_5d65c_row17_col0\" class=\"data row17 col0\" >Passive Aggressive Regressor</td>\n",
       "      <td id=\"T_5d65c_row17_col1\" class=\"data row17 col1\" >1.7037</td>\n",
       "      <td id=\"T_5d65c_row17_col2\" class=\"data row17 col2\" >4.6140</td>\n",
       "      <td id=\"T_5d65c_row17_col3\" class=\"data row17 col3\" >2.1341</td>\n",
       "      <td id=\"T_5d65c_row17_col4\" class=\"data row17 col4\" >-0.1591</td>\n",
       "      <td id=\"T_5d65c_row17_col5\" class=\"data row17 col5\" >0.4792</td>\n",
       "      <td id=\"T_5d65c_row17_col6\" class=\"data row17 col6\" >0.5724</td>\n",
       "      <td id=\"T_5d65c_row17_col7\" class=\"data row17 col7\" >0.0440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7868c853fd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
       "                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                    max_samples=None, min_impurity_decrease=0.0,\n",
       "                    min_impurity_split=None, min_samples_leaf=1,\n",
       "                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                    n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                    random_state=3307, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pycaret.regression import *\n",
    "\n",
    "# 機械学習前の下準備を行う。以下、Pycaretの関数を使う場合このセルを実行してから使うこと\n",
    "print(\"機械学習の準備中・・・\")\n",
    "\n",
    "mfcc_data = pd.read_csv(\"mfcc.csv\") # MFCCのデータを読み込む\n",
    "# データの前準備(以下、Pycaretの関数を使う場合setupを呼び出してから使うこと)\n",
    "reg = setup(data=mfcc_data, target='target', data_split_shuffle=True, use_gpu=True, silent=True, fold=5, n_jobs=-1)\n",
    "\n",
    "print(\"準備完了\")\n",
    "\n",
    "# 機械学習のモデルを複数比較し、精度が高かったモデルを表示する。\n",
    "print(\"最適モデルを検索中・・・\")\n",
    "\n",
    "compare_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデルを作成中・・・\n",
      "テストデータで予測中・・・\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5f7d4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5f7d4_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_5f7d4_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_5f7d4_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_5f7d4_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_5f7d4_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_5f7d4_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_5f7d4_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5f7d4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5f7d4_row0_col0\" class=\"data row0 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_5f7d4_row0_col1\" class=\"data row0 col1\" >0.8275</td>\n",
       "      <td id=\"T_5f7d4_row0_col2\" class=\"data row0 col2\" >1.3275</td>\n",
       "      <td id=\"T_5f7d4_row0_col3\" class=\"data row0 col3\" >1.1522</td>\n",
       "      <td id=\"T_5f7d4_row0_col4\" class=\"data row0 col4\" >0.6677</td>\n",
       "      <td id=\"T_5f7d4_row0_col5\" class=\"data row0 col5\" >0.2744</td>\n",
       "      <td id=\"T_5f7d4_row0_col6\" class=\"data row0 col6\" >0.3449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7868b599e7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=[],\n",
       "                                       display_types=False, features_todrop=[],\n",
       "                                       id_columns=[], ml_usecase='regression',\n",
       "                                       numerical_features=[], target='target',\n",
       "                                       time_features=[])),\n",
       "                 ('imputer',\n",
       "                  Simple_Imputer(categorical_strategy='not_available',\n",
       "                                 fill_value_categorical=None,\n",
       "                                 fill_value_numerical=None,\n",
       "                                 numeric_strategy...\n",
       "                  ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0,\n",
       "                                      criterion='mse', max_depth=None,\n",
       "                                      max_features='auto', max_leaf_nodes=None,\n",
       "                                      max_samples=None,\n",
       "                                      min_impurity_decrease=0.0,\n",
       "                                      min_impurity_split=None,\n",
       "                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                      min_weight_fraction_leaf=0.0,\n",
       "                                      n_estimators=100, n_jobs=-1,\n",
       "                                      oob_score=False, random_state=3307,\n",
       "                                      verbose=0, warm_start=False)]],\n",
       "          verbose=False),\n",
       " 'Final Model.pkl')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycaret.regression import *\n",
    "# 最も精度が高かったモデルを生成\n",
    "tuned_model = 0\n",
    "\n",
    "print(\"モデルを作成中・・・\")\n",
    "model = create_model('et', verbose=False) # モデルを生成\n",
    "#print(\"モデルを調整中・・・\")\n",
    "#tuned_model = tune_model(model, optimize=\"R2\") # モデルを調整...すると精度落ちるの何...しないほうがいいのか？\n",
    "print(\"テストデータで予測中・・・\")\n",
    "predict_data = predict_model(tuned_model or model) # 既存のデータで予測\n",
    "predict_data.to_csv('predict_result.csv', index=False)  # csvで保存\n",
    "\n",
    "final_model = finalize_model(model)\n",
    "save_model(final_model,'Final Model')#モデルを保存\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "from pycaret.regression import *\n",
    "\n",
    "final_model = load_model('Final Model') # モデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "録音開始\n",
      "録音終了\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8879/3780763905.py:18: RuntimeWarning: invalid value encountered in true_divide\n",
      "  data = data / data.max() * np.iinfo(np.int16).max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCCを抽出しています・・・\n",
      "処理完了\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8879/3780763905.py:43: FutureWarning: Pass y=[0. 0. 0. ... 0. 0. 0.], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mfcc = librosa.feature.mfcc(y, sr)  # MFCC\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "#音声を録音\n",
    "\n",
    "FILE_NAME = 'my_recording.wav'  # 保存するファイル名\n",
    "wave_length = 5  # 録音する長さ（秒）\n",
    "sample_rate = 16_000  # サンプリング周波数\n",
    "\n",
    "print(\"録音開始\")\n",
    "# 録音開始（wave_length秒間録音。wait で録音し終わるまで待つ）\n",
    "data = sd.rec(int(wave_length * sample_rate), sample_rate, channels=1)\n",
    "sd.wait()\n",
    "print(\"録音終了\")\n",
    "\n",
    "# ノーマライズ。量子化ビット16bitで録音するので int16 の範囲で最大化する\n",
    "data = data / data.max() * np.iinfo(np.int16).max\n",
    "\n",
    "# float -> int\n",
    "data = data.astype(np.int16)\n",
    "\n",
    "# ファイル保存\n",
    "with wave.open(FILE_NAME, mode='wb') as wb:\n",
    "    wb.setnchannels(1)  # モノラル\n",
    "    wb.setsampwidth(2)  # 16bit=2byte\n",
    "    wb.setframerate(sample_rate)\n",
    "    wb.writeframes(data.tobytes())  # バイト列に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCCを抽出しています・・・\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>mfcc_11</th>\n",
       "      <th>mfcc_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.788544</td>\n",
       "      <td>-11.775072</td>\n",
       "      <td>20.867018</td>\n",
       "      <td>-1.403565</td>\n",
       "      <td>2.142157</td>\n",
       "      <td>-3.157141</td>\n",
       "      <td>4.668924</td>\n",
       "      <td>-11.96955</td>\n",
       "      <td>8.3155</td>\n",
       "      <td>-12.742859</td>\n",
       "      <td>4.376723</td>\n",
       "      <td>-9.088756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mfcc_1     mfcc_2     mfcc_3    mfcc_4    mfcc_5    mfcc_6    mfcc_7  \\\n",
       "0  69.788544 -11.775072  20.867018 -1.403565  2.142157 -3.157141  4.668924   \n",
       "\n",
       "     mfcc_8  mfcc_9    mfcc_10   mfcc_11   mfcc_12  \n",
       "0 -11.96955  8.3155 -12.742859  4.376723 -9.088756  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "###MFCCを抽出###\n",
    "print(\"MFCCを抽出しています・・・\")\n",
    "\n",
    "data = []\n",
    "TEST_FILE_NAME = \"TestSample/hanae2.wav\"\n",
    "\n",
    "test = True\n",
    "\n",
    "y, sr = librosa.load(TEST_FILE_NAME if test else FILE_NAME)  # 音声ファイルを読み込む\n",
    "mfcc = librosa.feature.mfcc(y, sr)  # MFCC\n",
    "mfcc = np.average(mfcc, axis=1)  # 時間平均を取る\n",
    "mfcc = mfcc.flatten()\n",
    "mfcc = mfcc.tolist()\n",
    "mfcc = mfcc[1:13]  # 低次の係数を取り出す（12次まで取り出すことが多い）\n",
    "data.append(mfcc)\n",
    "\n",
    "df = pd.DataFrame(data, columns=[f'mfcc_{n}' for n in range(1, 13)])\n",
    "\n",
    "df.to_csv('mfcc_my_recording.csv', index=False)  # csvで保存\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "あなたの声は梶裕貴に似ています。\n",
      "予測値：2.72\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal, ROUND_HALF_UP, ROUND_HALF_EVEN\n",
    "from pycaret.regression import *\n",
    "\n",
    "#録音した音声データからどの声優に似ているかを特定\n",
    "\n",
    "actors = [\"下野紘\", \"花江夏樹\", \"梶裕貴\", \"沢城みゆき\", \"鬼頭明里\", \"水瀬いのり\", \"悠木碧\"]\n",
    "\n",
    "predict_my_recording = predict_model(final_model, data = pd.read_csv(\"mfcc_my_recording.csv\")) # 未知データを予測\n",
    "predict_label = predict_my_recording.at[0, \"Label\"] # 予測データを取得（小数点数）\n",
    "voice_actor_number = Decimal(str(predict_label)).quantize(Decimal('0'), rounding=ROUND_HALF_UP) # 整数に四捨五入\n",
    "print(\"あなたの声は\" + actors[int(voice_actor_number-1)] + \"に似ています。\")\n",
    "print(\"予測値：\" + str(predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%完了\n",
      "1人目のデータを処理中・・・\n",
      "（進行度:1/5ファイル）\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/librosa/core/audio.py:164\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[1;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    167\u001b[0m     \u001b[39m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/librosa/core/audio.py:195\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     \u001b[39m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     context \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39;49mSoundFile(path)\n\u001b[1;32m    197\u001b[0m \u001b[39mwith\u001b[39;00m context \u001b[39mas\u001b[39;00m sf_desc:\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/soundfile.py:655\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    654\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 655\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(file, mode_int, closefd)\n\u001b[1;32m    656\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[1;32m    657\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/soundfile.py:1213\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     err \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1213\u001b[0m     \u001b[39mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError opening \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[1;32m   1214\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1215\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening 'TestSample/001/.gitkeep': Format not recognised.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m（進行度:\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mfiles_number\u001b[39m}\u001b[39;00m\u001b[39mファイル）\u001b[39m\u001b[39m\"\u001b[39m )\n\u001b[1;32m     20\u001b[0m file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dir_name, file_list[i])  \u001b[39m# 音声ファイルへのパス\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m y, sr \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(file_path)  \u001b[39m# 音声ファイルを読み込む\u001b[39;00m\n\u001b[1;32m     22\u001b[0m mfcc \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mfeature\u001b[39m.\u001b[39mmfcc(y, sr)  \u001b[39m# MFCC\u001b[39;00m\n\u001b[1;32m     23\u001b[0m mfcc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage(mfcc, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# 時間平均を取る\u001b[39;00m\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/librosa/core/audio.py:170\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPurePath)):\n\u001b[1;32m    169\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[39m\"\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m--> 170\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[1;32m    171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/librosa/core/audio.py:226\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    223\u001b[0m     reader \u001b[39m=\u001b[39m path\n\u001b[1;32m    224\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[39m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     reader \u001b[39m=\u001b[39m audioread\u001b[39m.\u001b[39;49maudio_open(path)\n\u001b[1;32m    228\u001b[0m \u001b[39mwith\u001b[39;00m reader \u001b[39mas\u001b[39;00m input_file:\n\u001b[1;32m    229\u001b[0m     sr_native \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39msamplerate\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/audioread/__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m BackendClass \u001b[39min\u001b[39;00m backends:\n\u001b[1;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m BackendClass(path)\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    129\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/jouhou1hann/voicepro/lib/python3.9/site-packages/audioread/rawread.py:62\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m aifc\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fh)\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m aifc\u001b[39m.\u001b[39mError:\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Return to the beginning of the file to try the next reader.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.9/aifc.py:917\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    915\u001b[0m         mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    916\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 917\u001b[0m     \u001b[39mreturn\u001b[39;00m Aifc_read(f)\n\u001b[1;32m    918\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m Aifc_write(f)\n",
      "File \u001b[0;32m/usr/lib/python3.9/aifc.py:358\u001b[0m, in \u001b[0;36mAifc_read.__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m     \u001b[39m# assume it is an open file object already\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitfp(f)\n",
      "File \u001b[0;32m/usr/lib/python3.9/aifc.py:314\u001b[0m, in \u001b[0;36mAifc_read.initfp\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_soundpos \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m file\n\u001b[0;32m--> 314\u001b[0m chunk \u001b[39m=\u001b[39m Chunk(file)\n\u001b[1;32m    315\u001b[0m \u001b[39mif\u001b[39;00m chunk\u001b[39m.\u001b[39mgetname() \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFORM\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    316\u001b[0m     \u001b[39mraise\u001b[39;00m Error(\u001b[39m'\u001b[39m\u001b[39mfile does not start with FORM id\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.9/chunk.py:63\u001b[0m, in \u001b[0;36mChunk.__init__\u001b[0;34m(self, file, align, bigendian, inclheader)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunkname \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread(\u001b[39m4\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunkname) \u001b[39m<\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunksize \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack_from(strflag\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m, file\u001b[39m.\u001b[39mread(\u001b[39m4\u001b[39m))[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "#声優の声データからMFCC（声の特徴量）を抽出し、表にまとめる。\n",
    "\n",
    "X_data = []  # 特徴行列\n",
    "speakers_number = 7 # 声優の人数\n",
    "files_number = 5 #声優一人あたりのファイル数\n",
    "\n",
    "for speaker_num in range(1, speakers_number + 1):  # 声優フォルダの数だけ繰り返し処理\n",
    "    # ボイスサンプルがあるフォルダ名\n",
    "    dir_name = f'TestSample/{str(speaker_num).zfill(3)}'\n",
    "    file_list = os.listdir(dir_name)\n",
    "    for i in range(files_number):\n",
    "        print(f\"{int((i+(speaker_num-1)*files_number)/(files_number*speakers_number)*100)}%完了\")\n",
    "        print(str(speaker_num) + \"人目のデータを処理中・・・\")\n",
    "        print(f\"（進行度:{i+1}/{files_number}ファイル）\" )\n",
    "        file_path = os.path.join(dir_name, file_list[i])  # 音声ファイルへのパス\n",
    "        y, sr = librosa.load(file_path)  # 音声ファイルを読み込む\n",
    "        mfcc = librosa.feature.mfcc(y, sr)  # MFCC\n",
    "        mfcc = np.average(mfcc, axis=1)  # 時間平均を取る\n",
    "        mfcc = mfcc.flatten()\n",
    "        mfcc = mfcc.tolist()\n",
    "        mfcc = mfcc[1:13]  # 低次の係数を取り出す（12次まで取り出すことが多い）\n",
    "        X_data.append(mfcc)\n",
    "\n",
    "df = pd.DataFrame(X_data, columns=[f'mfcc_{n}' for n in range(1, 13)]) # mfcc_1,mfcc_2,..のように行のタイトルをつける\n",
    "\n",
    "df.to_csv('mfcc_test.csv', index=False)  # csvで保存\n",
    "df.head() # 見せてほしいな"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m actors \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m下野紘\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m花江夏樹\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m梶裕貴\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m沢城みゆき\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m鬼頭明里\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m水瀬いのり\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m悠木碧\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m speakers_number \u001b[39m=\u001b[39m actors\u001b[39m.\u001b[39;49mlength\n\u001b[1;32m      9\u001b[0m final_model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39m\u001b[39mFinal Model\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m results \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'length'"
     ]
    }
   ],
   "source": [
    "from pycaret.regression import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "actors = [\"下野紘\", \"花江夏樹\", \"梶裕貴\", \"沢城みゆき\", \"鬼頭明里\", \"水瀬いのり\", \"悠木碧\"]\n",
    "speakers_number = 7\n",
    "\n",
    "final_model = load_model('Final Model')\n",
    "results = []\n",
    "\n",
    "#学習に使用していない声優の声データを用いて正答率を出す。\n",
    "testFolder = \"TestSample\"\n",
    "folders = os.listdir(testFolder)\n",
    "\n",
    "for speaker_num in range(1, speakers_number):\n",
    "    files = os.listdir(f'{testFolder}/{str(speaker_num).zfill(3)}')\n",
    "    for testFile in files:\n",
    "        print(f'{speaker_num}/{speakers_number}人完了')\n",
    "        predict_data = predict_model(final_model, data = pd.read_csv(\"mfcc_my_recording.csv\")) # 未知データを予測\n",
    "        predict_label = predict_my_recording.at[0, \"Label\"] # 予測データを取得（小数点数）\n",
    "        voice_actor_number = Decimal(str(predict_label)).quantize(Decimal('0'), rounding=ROUND_HALF_UP) # 整数に四捨五入\n",
    "        result = [actors[voice_actor_number], predict_label, f'{actors[speaker_num]}({speaker_num})']\n",
    "        print(\"result\")\n",
    "        results.append(result)\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"予想した声優\", \"予測値\", \"正解値\"])\n",
    "df.to_csv(\"test_result.csv\", index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voicepro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f851e7d60498e4c856c45d591b0ef68acd2607c354303225ef1533b02fefcf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
